{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be6dc48-01cb-4c1b-8d0f-5d9b0cabc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'../functions/')\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import data_sim\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import copy\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from slab_spike_model_constructor import *\n",
    "from full_slab_spike_model_constructor import *\n",
    "from training_func import *\n",
    "import pyreadr\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c452c-2391-4783-8dc8-954988727540",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57222f33-d2ce-42ed-b22e-aa6c3f9268ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD = pd.read_csv('../dataset/abcd.csv')\n",
    "abcd_full_outcome = pd.read_csv('../dataset/DEAP-data-download.csv')\n",
    "list_ROI = pyreadr.read_r('../dataset/ABCD_ROI.list.RData')\n",
    "# Join the covariates with the outcome \n",
    "ABCD.drop(columns = ['Unnamed: 0','cbcl_scr_syn_internal_t','cbcl_scr_syn_anxdep_t', 'abcl_scr_sub_use_alcohol_t'], inplace = True)\n",
    "abcd_full_outcome.drop(columns = ['race.6level', 'female'], inplace = True)\n",
    "ABCD = ABCD.merge(abcd_full_outcome, how = 'left', left_on = ['subjectid','eventname'], right_on = ['src_subject_id', 'event_name'])\n",
    "ABCD.drop(columns = ['Unnamed: 0'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbadce-0dcf-4a5f-988c-e21860e3b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af6b3a-c372-4be5-a7e8-51a8bb86db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from sklearn.linear_model import LassoCV,RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class inference_on_data(object):\n",
    "    def __init__(self, data, outcome_vars, \n",
    "                  modality_vars, modality_vars_dict, \n",
    "                  lr = 0.05, batch_size = None, tobit = True, \n",
    "                  device = 'cpu', random_seed = 1):\n",
    "        self.data = data\n",
    "        self.outcome_vars = outcome_vars\n",
    "        self.modality_vars = modality_vars\n",
    "        self.modality_vars_dict = modality_vars_dict\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.tobit = True\n",
    "        self.device = device\n",
    "        self.random_seed = 1\n",
    "    \n",
    "    def plot_and_summary(self, ABCD_sub, outcome_name, modality_name, save_location = '../application/'):\n",
    "        # ABCD_sub should be the clean version of the data after sampling\n",
    "        \n",
    "        # Plotting\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        ax1 = sns.histplot(ax = axs[0],data = ABCD_sub[outcome_name], bins = 20)\n",
    "        ax2 = sns.heatmap(ax = axs[1],data = pd.DataFrame(ABCD_sub[list(np.squeeze(self.modality_vars_dict[modality_name].values,1))]).corr(),\n",
    "                   xticklabels = False, yticklabels = False\n",
    "                   )\n",
    "        ax1.set(xlabel=outcome_name)\n",
    "        ax2.set(xlabel=modality_name+' ROI measures \\n correlation matrix')\n",
    "        plt.tight_layout(w_pad=2)\n",
    "        plt.axis('scaled')\n",
    "        cur_name = outcome_name+'_'+modality_name\n",
    "        fig.savefig(save_location+'figures/'+ cur_name+'_ill_plot' +'.png',dpi = 300)\n",
    "        \n",
    "        # Print and write the summary of the dataset\n",
    "        N = ABCD_sub.shape[0]\n",
    "        p = len(self.modality_vars_dict[modality_name])\n",
    "        save_text = f'The number of subjects is {N} and the number of MRI features is {p} for {cur_name} pair'\n",
    "        with open(save_location+cur_name+'_N_p.txt', 'w') as f:\n",
    "            # Write some text to the file\n",
    "            f.write(save_text)\n",
    "        print(save_text)\n",
    "    \n",
    "    def run(self, outcome_name, modality_name):\n",
    "        image_var = list(np.squeeze(self.modality_vars_dict[modality_name].values,1))\n",
    "        cov = image_var.copy()\n",
    "        cov.extend([outcome_name,'eventname',\n",
    "            \"mri_info_manufacturers.model.name\", 'race.6level', 'age', 'female', 'subjectid', 'demo_rel_family_id.bl'])\n",
    "        #import pdb; pdb.set_trace()\n",
    "        # getting the relevent columns\n",
    "        ABCD_sub = self.data.loc[:,np.isin(self.data.columns,cov)]\n",
    "        # getting the subjects without na\n",
    "        ABCD_sub = ABCD_sub.loc[~ABCD_sub.isnull().any(axis = 1),:]\n",
    "        # sample one subject in the families\n",
    "        ABCD_sub = ABCD_sub.groupby('demo_rel_family_id.bl', \n",
    "                                    group_keys=False).apply(lambda x: x.sample(1, random_state = self.random_seed)).reset_index(drop=True)\n",
    "        # sample one subject in the visit\n",
    "        ABCD_sub = ABCD_sub.groupby(['subjectid','eventname'], \n",
    "                                    group_keys=False).apply(lambda x: x.sample(1, random_state = self.random_seed)).reset_index(drop=True)\n",
    "        # drop the subjectid and family id\n",
    "        ABCD_sub.drop(columns = ['subjectid', 'demo_rel_family_id.bl','eventname'], inplace=True)\n",
    "        # Onehotencode the categorical variables\n",
    "        cate_cov = ['race.6level', 'female',\"mri_info_manufacturers.model.name\"]\n",
    "        OHE = OneHotEncoder(drop = 'first',sparse_output = False).fit(ABCD_sub[cate_cov])\n",
    "        encoded_cols = list(OHE.get_feature_names_out(cate_cov))\n",
    "        ABCD_sub[encoded_cols] = OHE.transform(ABCD_sub[cate_cov])\n",
    "        # Confounders variable\n",
    "        confounders = encoded_cols+['age']\n",
    "        # plot and print basic information\n",
    "        self.plot_and_summary(ABCD_sub,outcome_name = outcome_name, modality_name = modality_name)\n",
    "        # Setting up the numpy array\n",
    "        X = ABCD_sub[confounders+image_var].to_numpy()\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        z = ABCD_sub[outcome_name].to_numpy() \n",
    "        # smallest value at 0\n",
    "        z = z- min(z)\n",
    "        p_confound = len(confounders)\n",
    "        # Train test split\n",
    "        X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=42)\n",
    "\n",
    "        p = X_train.shape[1] - p_confound\n",
    "        n = X_train.shape[0]\n",
    "        # Model setup\n",
    "        if self.batch_size == None:\n",
    "            batch_size = X.shape[0]\n",
    "        else:\n",
    "            batch_size = batch_size\n",
    "        #import pdb; pdb.set_trace()\n",
    "        # Lasso\n",
    "        reg = LassoCV(cv = 5, alphas = (1,10))\n",
    "        reg.fit(X_train,z_train)\n",
    "        z_pred = reg.predict(X_test)\n",
    "        mae_lasso = np.mean(np.abs(z_pred*(z_pred>0)-z_test))\n",
    "        # Ridge\n",
    "        reg = RidgeCV(cv = 5, alphas = (1,10))\n",
    "        reg.fit(X_train,z_train)\n",
    "        z_pred = reg.predict(X_test)\n",
    "        mae_ridge = np.mean(np.abs(z_pred*(z_pred>0)-z_test))\n",
    "        exact_lh = True\n",
    "        tobit = self.tobit\n",
    "        X_train = torch.tensor(X_train)\n",
    "        z_train = torch.tensor(z_train)\n",
    "        X_test = torch.tensor(X_test)\n",
    "        z_test = torch.tensor(z_test)\n",
    "        sim_data = Sim_Dataset(X_train, z_train, device = self.device)\n",
    "        sim_data_loader = DataLoader(sim_data, batch_size = batch_size)\n",
    "        true_beta = np.zeros((p,))\n",
    "        model = linear_slab_spike(p = p, n_total = n, p_confound = p_confound,init_pi_local_max = 1.0, \n",
    "                                  init_pi_local_min = 0.0,init_pi_global = 0.5, init_beta_var =1, init_noise_var = 1,\n",
    "                                  gumbel_softmax_temp = 1, gumbel_softmax_hard = False, \n",
    "                                  a1= 0.1, a2=0.1, init_a3= 1.1, init_a4 = 1.1,\n",
    "                                  b1 = 1.1, b2 = 1.1, init_b3 = 10.0, init_b4 = 0.1, n_E = 1\n",
    "                                  , prior_sparsity = True, prior_sparsity_beta = False,\n",
    "                                  exact_lh = exact_lh,tobit = self.tobit, device = self.device\n",
    "                                 ).double().to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr = 0.5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.8)\n",
    "        t = 100 #number of moving averages\n",
    "        patience = 200# patience\n",
    "        best_model, error, point_est, result_dict = train_and_infer(model = model, optimizer = optimizer,\n",
    "                                                                    sim_data_loader = sim_data_loader, \n",
    "                                                                    lr_scheduler = lr_scheduler, t = t, \n",
    "                                                                    patience = patience,X = X, plot = True, \n",
    "                                                                    true_beta = true_beta, lr_schedule_step = 1000,\n",
    "                                                                    verbose = False)\n",
    "        pi_local_est = torch.sigmoid(best_model.logit_pi_local)\n",
    "        beta_est = best_model.beta_mu\n",
    "        top_k_pi, indices = torch.topk(pi_local_est, 10)\n",
    "        top_k_beta_est = beta_est[indices].cpu().detach().numpy()\n",
    "        top_k_pi = top_k_pi.cpu().detach().numpy()\n",
    "        indices = indices.numpy()\n",
    "        top_k_name = np.array(image_var)[indices]\n",
    "        dict_top_k = {'outcome': np.repeat(outcome_name, len(top_k_name)),\n",
    "                      'modality':np.repeat(modality_name, len(top_k_name)),\n",
    "                      'var_name': top_k_name, 'pi':top_k_pi, 'beta_mu': top_k_beta_est}\n",
    "        dict_beta_pi = {'beta':beta_est.cpu().detach().numpy(),'pi': pi_local_est.cpu().detach().numpy()}\n",
    "        result_dict['outcome']=outcome_name\n",
    "        result_dict['modality'] = modality_name\n",
    "        z_pred = best_model.predict(X_test)\n",
    "        result_dict['mae'] = np.mean(np.abs(z_pred*(z_pred>0) - z_test.cpu().detach().numpy()))\n",
    "        result_dict['mae_lasso'] = mae_lasso\n",
    "        result_dict['mae_ridge'] = mae_ridge\n",
    "        #import pdb; pdb.set_trace()\n",
    "        # Transform to dataframe\n",
    "        result_df = pd.DataFrame(result_dict)\n",
    "        top_k_df = pd.DataFrame(dict_top_k)\n",
    "        return result_df, top_k_df, dict_beta_pi, point_est\n",
    "    \n",
    "    def full_run(self,save_path = ''):\n",
    "        result_df_l = []\n",
    "        top_k_df_l = []\n",
    "        for o in self.outcome_vars:\n",
    "            for m in self.modality_vars:\n",
    "                result_df, top_k_df, dict_beta_pi, point_est = self.run(o, m)\n",
    "                #import pdb;pdb.set_trace()\n",
    "                result_df_l.append(result_df)\n",
    "                top_k_df_l.append(top_k_df)\n",
    "        total_result = pd.concat(result_df_l)\n",
    "        top_k_result = pd.concat(top_k_df_l)\n",
    "        total_result.to_csv(os.path.join(save_path, 'ABCD_h_sparsity.csv'))\n",
    "        top_k_result.to_csv(os.path.join(save_path, 'ABCD_top_k_variable.csv'))\n",
    "        return total_result, top_k_result\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01230479-45f0-43d4-8806-0b53c97d77d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome_vars = ['aeq_positive_expectancies_ss']\n",
    "modality_vars = ['rsmri_list', 'tfmri_list', 'smri_list', 'dti_list', 'rsi_list']\n",
    "temp = inference_on_data(data = ABCD,  \n",
    "                         outcome_vars = outcome_vars, \n",
    "                         modality_vars = modality_vars,\n",
    "                         modality_vars_dict = list_ROI)\n",
    "total_result, top_k_result = temp.full_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4f220-57d3-443a-997e-dce160a252d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
